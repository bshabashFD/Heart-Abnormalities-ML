{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from boris_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Dataset\n",
    "\n",
    "First thing's first, let's load the dataset. I created a new function that loads up the dataset for me and converts it into a pandas dataframe for easy access. For more information on this, please see the `Data Cleaning` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_and_combine_data('453_923_bundle_archive', read_noisy_data=False)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the class distribution to see if there is any concern of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = dataset['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.barh(label_counts.index, label_counts.values)\n",
    "plt.xlabel(\"Value Counts\")\n",
    "plt.ylabel(\"Condition\")\n",
    "plt.title(\"The Distribution of Different Labels in the Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is certainly an issue of class imbalance here. A naive classifier could guess pretty well by simply guessing \"Normal\" on all the examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all Abnormalities\n",
    "\n",
    "Let's try a simple example first, we will combine all abnormalities into a single label \"abnormal\". We won't count artifacts in that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relabel(label):\n",
    "    if (label == \"normal\"):\n",
    "        return \"normal\"\n",
    "    else:\n",
    "        return \"abnormal\"\n",
    "dataset['label'] = dataset['label'].apply(relabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = dataset['label'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.barh(label_counts.index, label_counts.values)\n",
    "plt.xlabel(\"Value Counts\")\n",
    "plt.ylabel(\"Condition\")\n",
    "plt.title(\"The Distribution of Different Labels in the Re-labeled Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our data now into a simple train/test stratified split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.3, stratify=dataset['label'], random_state=1)\n",
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Augmentation\n",
    "\n",
    "We won't get very far with the examples we have. There aren't very many of them\n",
    "\n",
    "Luckily, we can easily augment the dataset by shifting the data and/or adding some noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TARGET = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the label ratios\n",
    "inverse_counts = 1/train_dataset['label'].value_counts()\n",
    "probability_counts = inverse_counts/inverse_counts.sum()\n",
    "probability_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6\n",
    "    \n",
    "def shift_sound(data, sampling_rate, shift_max, shift_direction='both'):\n",
    "    shift = np.random.randint(int(shift_max * data.shape[0]))\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data = augmented_data[shift:]\n",
    "    else:\n",
    "        augmented_data = augmented_data[:shift]\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = np.random.choice(probability_counts.index, \n",
    "                           p=probability_counts.values, \n",
    "                           size=(DATASET_TARGET,))\n",
    "i = 0\n",
    "while train_dataset.shape[0] < DATASET_TARGET:\n",
    "    choice = choices[i]\n",
    "    available_instances = train_dataset[train_dataset['label'] == choice]\n",
    "    selected_row_position = np.random.randint(available_instances.shape[0])\n",
    "    \n",
    "    selected_row = available_instances.iloc[selected_row_position]\n",
    "    \n",
    "    base_signal = selected_row['signal']\n",
    "    sampling_rate = selected_row['sampling_rate']\n",
    "    \n",
    "    shift_direction = 'both'\n",
    "    new_signal = shift_sound(base_signal, sampling_rate, (np.random.random()*0.3), shift_direction)\n",
    "    if (new_signal.shape[0] > 0):\n",
    "    \n",
    "        new_series = pd.Series({'signal' :new_signal, 'sampling_rate': sampling_rate, 'label': choice})\n",
    "        train_dataset = train_dataset.append(new_series, ignore_index=True)\n",
    "    \n",
    "        print(train_dataset.shape, end=\"\\r\")\n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define a class which will convert the signals into Mel spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelEncoder:\n",
    "    \n",
    "    '''\n",
    "        This transformer takes an audio signal and employes librosa\n",
    "        to transform the audio signal into a Mel-frequency spectrogram.\n",
    "        \n",
    "        The transformation transforms the audio signal from samples in a \n",
    "        time domain, to frequencies over each time window. The frequencies\n",
    "        are then collected into buckets which are easily distinguished by\n",
    "        human hearing\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, flatten=True, n_fft=2048, hop_length=512, n_mels=128, sampling_rate=22050.0, n_windows=1000, verbose=0):\n",
    "        \n",
    "        \n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_mels = n_mels\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.n_windows = n_windows\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        \n",
    "        self.flatten = flatten\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "            This method doesn't do much except initialize\n",
    "        '''\n",
    "        self.longest_signal_length = None\n",
    "        \n",
    "    \n",
    "    \n",
    "    def _create_spectrogram_list(self, X):\n",
    "        \n",
    "        spectrogram_list = []\n",
    "        \n",
    "        \n",
    "        for i, signal in enumerate(X):\n",
    "                mel_spectrogram = self._signal_to_mel_spectrogram(signal)\n",
    "                spectrogram_list.append(mel_spectrogram)\n",
    "                if (self.verbose):\n",
    "                    print(f\"processed: {round(100*i/X.shape[0], 2)}%\", end=\"\\r\")\n",
    "                    \n",
    "                \n",
    "        print(f\"processed: {round(100*i/X.shape[0], 2)}%\")\n",
    "        \n",
    "        return spectrogram_list\n",
    "    \n",
    "    \n",
    "    def _find_longest_signal_length(self, spectrogram_list):\n",
    "        \n",
    "        max_length = 0\n",
    "        for mel_spectrogram in spectrogram_list:\n",
    "            if (mel_spectrogram.shape[1] > max_length):\n",
    "                max_length = mel_spectrogram.shape[1]\n",
    "\n",
    "        return max_length\n",
    "            \n",
    "    def _build_mel_spectrogram_stack(self, spectrogram_list):\n",
    "        \n",
    "        X_transformed = np.zeros((len(spectrogram_list), self.n_mels, self.longest_signal_length))\n",
    "        \n",
    "        for i, mel_spectrogram in enumerate(spectrogram_list):\n",
    "            if (mel_spectrogram.shape[1] <= self.longest_signal_length):\n",
    "                X_transformed[i, :, -mel_spectrogram.shape[1]:] = mel_spectrogram[:, :]\n",
    "            else:\n",
    "                X_transformed[i, :, :] = mel_spectrogram[:, -self.longest_signal_length:]\n",
    "                \n",
    "        return X_transformed\n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        spectrogram_list = self._create_spectrogram_list(X)\n",
    "        \n",
    "        if (self.longest_signal_length is None):\n",
    "            self.longest_signal_length = self._find_longest_signal_length(spectrogram_list)\n",
    "            \n",
    "        X_transformed = self._build_mel_spectrogram_stack(spectrogram_list)\n",
    "        \n",
    "        \n",
    "        if (self.flatten):\n",
    "            return X_transformed.reshape(X_transformed.shape[0], -1)\n",
    "        else:\n",
    "            return X_transformed\n",
    "        \n",
    "        \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X).transform(X)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    # https://towardsdatascience.com/getting-to-know-the-mel-spectrogram-31bca3e2d9d0\n",
    "    def _longest_signal(self, signals):\n",
    "        max_length = 0\n",
    "        for signal in signals:\n",
    "            if (len(signal) > max_length):\n",
    "                max_length = len(signal)\n",
    "\n",
    "        return max_length\n",
    "    \n",
    "    \n",
    "    def _signal_to_mel_spectrogram(self, signal):\n",
    "        \n",
    "        \n",
    "        if (self.n_windows is not None):\n",
    "            hop_length = signal.shape[0]//self.n_windows\n",
    "        else:\n",
    "            hop_length = self.hop_length\n",
    "        S = librosa.feature.melspectrogram(signal, \n",
    "                                           sr=self.sampling_rate, \n",
    "                                           n_fft=self.n_fft, \n",
    "                                           hop_length=hop_length, \n",
    "                                           n_mels=self.n_mels)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "        return S_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_encoder = MelEncoder(n_mels=128, n_windows=1000, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_encoder.fit(train_dataset['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_mel = my_encoder.transform(train_dataset['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test_mel = my_encoder.transform(test_dataset['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_mmscaler = MinMaxScaler()\n",
    "\n",
    "X_train_mel = my_mmscaler.fit_transform(X_train_mel)\n",
    "X_test_mel = my_mmscaler.transform(X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mel = X_train_mel\n",
    "X_train_mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "component_number = min(*X_train_mel.shape)\n",
    "my_pca = PCA(n_components=component_number, svd_solver='full')\n",
    "my_pca.fit(X_train_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(my_pca.explained_variance_ratio_.cumsum())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mel = my_pca.transform(X_train_mel)\n",
    "X_test_mel = my_pca.transform(X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model - Logistic Regression\n",
    "\n",
    "Let's start by establishing a baseline performance. I am just going to load the raw audio data as features (where each feature is an audio measurement) and see how well a simple logistic regression (linear model) and decision tree (non-linear model) will perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "y_train = condition_label_encoder.fit_transform(train_dataset['label'])[:X_train_mel.shape[0]]\n",
    "y_test = condition_label_encoder.transform(test_dataset['label'])\n",
    "\n",
    "print(X_train_mel.shape, X_test_mel.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "my_logit = LogisticRegression(random_state=1).fit(X_train_mel, y_train)\n",
    "train_acc = my_logit.score(X_train_mel, y_train)\n",
    "test_acc = my_logit.score(X_test_mel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training accuracy is {round(train_acc*100,2)}%\")\n",
    "print(f\"The test accuracy is {round(test_acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely suspicious results. There is clearly a very large sign of overfitting here. Let's explore how the logistic regression makes decisions.\n",
    "\n",
    "Let's plot the coefficients as if they were an audio mask (which is really what they end up becoming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_logit, X_test_mel, y_test,\n",
    "                             display_labels = condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None,\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_logit, X_test_mel, y_test,\n",
    "                             display_labels=condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true',\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [2**i for i in range(-17, 18)]}\n",
    "my_estimator = LogisticRegression(solver='saga')\n",
    "my_logit_gs = GridSearchCV(my_estimator, param_grid, cv=5, verbose=1, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "my_logit_gs.fit(X_train_mel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_logit_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = my_logit_gs.score(X_train_mel, y_train)\n",
    "test_acc = my_logit_gs.score(X_test_mel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training accuracy is {round(train_acc*100,2)}%\")\n",
    "print(f\"The test accuracy is {round(test_acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_logit_gs, X_test_mel, y_test,\n",
    "                             display_labels = condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None,\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_logit_gs, X_test_mel, y_test,\n",
    "                             display_labels=condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true',\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, my_logit_gs.predict(X_test_mel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = my_logit_gs.predict_proba(X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(y_proba[:, 1], y_test)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model - Support Vector Machine\n",
    "\n",
    "Let's start by establishing a baseline performance. I am just going to load the raw audio data as features (where each feature is an audio measurement) and see how well a simple logistic regression (linear model) and decision tree (non-linear model) will perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "y_train = condition_label_encoder.fit_transform(train_dataset['label'])[:X_train_mel.shape[0]]\n",
    "y_test = condition_label_encoder.transform(test_dataset['label'])\n",
    "\n",
    "print(X_train_mel.shape, X_test_mel.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "my_svm = SVC(random_state=1, max_iter=10000, probability=True).fit(X_train_mel, y_train)\n",
    "train_acc = my_svm.score(X_train_mel, y_train)\n",
    "test_acc = my_svm.score(X_test_mel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training accuracy is {round(train_acc*100,2)}%\")\n",
    "print(f\"The test accuracy is {round(test_acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [2**i for i in range(-17, 18)],\n",
    "              'kernel': ['poly', 'rbf', 'sigmoid']}\n",
    "my_estimator = SVC(max_iter=10000, probability=True)\n",
    "my_svm_gs = GridSearchCV(my_estimator, param_grid, cv=5, verbose=1, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "my_svm_gs.fit(X_train_mel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_svm_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = my_svm_gs.score(X_train_mel, y_train)\n",
    "test_acc = my_svm_gs.score(X_test_mel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training accuracy is {round(train_acc*100,2)}%\")\n",
    "print(f\"The test accuracy is {round(test_acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_svm_gs, X_test_mel, y_test,\n",
    "                             display_labels = condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None,\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_svm_gs, X_test_mel, y_test,\n",
    "                             display_labels=condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true',\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, my_svm_gs.predict(X_test_mel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = my_svm_gs.predict_proba(X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(y_proba[:, 1], y_test)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model - KNN\n",
    "\n",
    "Let's start by establishing a baseline performance. I am just going to load the raw audio data as features (where each feature is an audio measurement) and see how well a simple logistic regression (linear model) and decision tree (non-linear model) will perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "y_train = condition_label_encoder.fit_transform(train_dataset['label'])[:X_train_mel.shape[0]]\n",
    "y_test = condition_label_encoder.transform(test_dataset['label'])\n",
    "\n",
    "print(X_train_mel.shape, X_test_mel.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "my_knn = KNN().fit(X_train_mel, y_train)\n",
    "train_acc = my_knn.score(X_train_mel, y_train)\n",
    "test_acc = my_knn.score(X_test_mel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training accuracy is {round(train_acc*100,2)}%\")\n",
    "print(f\"The test accuracy is {round(test_acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely suspicious results. There is clearly a very large sign of overfitting here. Let's explore how the logistic regression makes decisions.\n",
    "\n",
    "Let's plot the coefficients as if they were an audio mask (which is really what they end up becoming)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_knn, X_test_mel, y_test,\n",
    "                             display_labels = condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None,\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_knn, X_test_mel, y_test,\n",
    "                             display_labels=condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true',\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'knn__n_neighbors': [i for i in range(3,10)] + \\\n",
    "                             [i for i in range(10, 100, 5)] + \\\n",
    "                             [i for i in range(100, X_train_mel.shape[0]//2, 20)],\n",
    "              'knn__weights': ['uniform', 'distance']}\n",
    "\n",
    "my_pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                    ('knn', KNN(algorithm='auto'))])\n",
    "\n",
    "my_knn_gs = GridSearchCV(my_pipe, param_grid, cv=10, verbose=1, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "my_knn_gs.fit(X_train_mel, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_knn_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = my_knn_gs.score(X_train_mel, y_train)\n",
    "test_acc = my_knn_gs.score(X_test_mel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training accuracy is {round(train_acc*100,2)}%\")\n",
    "print(f\"The test accuracy is {round(test_acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_knn_gs, X_test_mel, y_test,\n",
    "                             display_labels = condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None,\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_knn_gs, X_test_mel, y_test,\n",
    "                             display_labels=condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true',\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Logit Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, my_knn_gs.predict(X_test_mel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = my_knn_gs.predict_proba(X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(y_proba[:, 1], y_test)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model - Decision Tree\n",
    "\n",
    "As another baseline, I will train a decision tree to see if introducing non-linearity to the learning process produces better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_mel.shape, X_test_mel.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Let's set some regularization otherwise we know the tree will overfit\n",
    "my_tree = DecisionTreeClassifier()\n",
    "param_grid = {'min_samples_leaf': [i for i in range(1, 20)],\n",
    "              'max_depth' : [i for i in range(1, X_train_mel.shape[1], X_train_mel.shape[1]//10)]+[None],\n",
    "              'max_features': [i/10 for i in range(2, 11, 2)]}\n",
    "\n",
    "my_tree_gs = GridSearchCV(my_tree, param_grid, cv=5, verbose=1, n_jobs=3)\n",
    "my_tree_gs.fit(X_train_mel, y_train)\n",
    "\n",
    "\n",
    "train_acc = my_tree_gs.score(X_train_mel, y_train)\n",
    "test_acc = my_tree_gs.score(X_test_mel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training accuracy is {round(train_acc*100,2)}%\")\n",
    "print(f\"The test accuracy is {round(test_acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better results! However, let's see how the model performs using the confusion matrix of the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_tree_gs, X_test_mel, y_test,\n",
    "                             display_labels = condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None,\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Decision Tree Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_tree_gs, X_test_mel, y_test,\n",
    "                             display_labels=condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true',\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Decision Tree Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As suspected, quite a bit of the classification seems to classify abnormal conditions and sounds as \"normal\" due to the sheer volume of that class, but interestingly, ~39% of the normal examples get misclassified as abnormalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, my_tree_gs.predict(X_test_mel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = my_tree_gs.predict_proba(X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(y_proba[:, 1], \n",
    "            y_test)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Model - Random Forest\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_mel.shape, X_test_mel.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Let's set some regularization otherwise we know the tree will overfit\n",
    "my_rf = RandomForestClassifier(min_samples_leaf=10, \n",
    "                               max_features=0.6,\n",
    "                               max_depth=901,\n",
    "                               random_state=1, \n",
    "                               n_estimators=350,\n",
    "                               verbose=1,\n",
    "                               n_jobs=3).fit(X_train_mel, y_train)\n",
    "\n",
    "\n",
    "train_acc = my_rf.score(X_train_mel, y_train)\n",
    "test_acc = my_rf.score(X_test_mel, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The training accuracy is {round(train_acc*100,2)}%\")\n",
    "print(f\"The test accuracy is {round(test_acc*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better results! However, let's see how the model performs using the confusion matrix of the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_rf, X_test_mel, y_test,\n",
    "                             display_labels = condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize=None,\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Gradient Boosting Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots(figsize=(7, 7))\n",
    "disp = plot_confusion_matrix(my_rf, X_test_mel, y_test,\n",
    "                             display_labels=condition_label_encoder.classes_,\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true',\n",
    "                             ax=ax)\n",
    "disp.ax_.set_title(\"Gradient Boosting Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, my_rf.predict(X_test_mel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = my_rf.predict_proba(X_test_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.scatter(y_proba[:, 1], \n",
    "            y_test)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
