{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Data Initial Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# will need this to read wav file\n",
    "from scipy.io.wavfile import read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in `set_a_df`\n",
    "\n",
    "Read in the first dataset. The naming convention on the files is different than the one on the in CSV which is used as the data dictionary. \n",
    "\n",
    "The following group of cells perform the following operations:\n",
    "1. Read files and drop unlabeled test set used on Kaggle\n",
    "2. Define a function `read_in_files` to read in files, ingest their raw audio, and output the raw audio to a dataframe\n",
    "3. Run the function `read_in_files` on the files in set_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files and drop unlabeled test set used on Kaggle\n",
    "set_a_df = pd.read_csv('453_923_bundle_archive/set_a.csv')\n",
    "\n",
    "# remove unlabeled files within each dataframe, all other files are named in the CSV\n",
    "# as they are on the hard drive\n",
    "set_a_df = set_a_df[~set_a_df['label'].isna()]\n",
    "set_a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function `read_in_files` to read in files, ingest their raw audio, \n",
    "# and output the raw audio to a dataframe\n",
    "\n",
    "def read_in_files(file_name_dataframe):\n",
    "    '''\n",
    "        This function accepts a dataframe which contains\n",
    "        file names as well as their labels. It reads in\n",
    "        the audio files' content and creates a new\n",
    "        dataframe with the signal in it and the labels\n",
    "        from the original file\n",
    "        \n",
    "        If the signal contains 10,000 measurements, the\n",
    "        resulting dataframe will have 10,001 columns\n",
    "        (10,000 measurements + 1 label)\n",
    "    '''\n",
    "    \n",
    "    # Step 1: Find the longest file and its size\n",
    "    max_size = 0\n",
    "    for i, row in file_name_dataframe.iterrows():\n",
    "        file_name = \"453_923_bundle_archive/\"+row['fname']\n",
    "\n",
    "        a = read(file_name)\n",
    "        file_as_array = np.array(a[1],dtype=float)\n",
    "        if max_size < file_as_array.shape[0]:\n",
    "            max_size = file_as_array.shape[0]\n",
    "\n",
    "    \n",
    "    print(f\"Longest file has {max_size} measurements\")\n",
    "\n",
    "    # Step two, create an empty placeholder for \n",
    "    # each file, fill in its data, and append it\n",
    "    # to a list\n",
    "    list_of_files = []\n",
    "\n",
    "    for i, row in file_name_dataframe.iterrows():\n",
    "        file_name = \"453_923_bundle_archive/\"+row['fname']\n",
    "\n",
    "        a = read(file_name)\n",
    "        file_as_array = np.array(a[1],dtype=float)\n",
    "\n",
    "        # The placeholder is the same size as the largest file\n",
    "        # so all resulting rows end up with as many column\n",
    "        # as the longest file\n",
    "        placeholder_array = np.zeros((max_size,))\n",
    "        placeholder_array[-file_as_array.shape[0]:] = file_as_array[:]\n",
    "\n",
    "        list_of_files.append(placeholder_array)\n",
    "\n",
    "    # Now we just convert the list of file data into\n",
    "    # a pandas dataframe\n",
    "\n",
    "    file_name_as_numbers_dataframe = pd.DataFrame(data=np.array(list_of_files))\n",
    "    file_name_as_numbers_dataframe['label'] = file_name_dataframe['label']\n",
    "    return file_name_as_numbers_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function `read_in_files` on the files in set_a\n",
    "set_a_as_number_df = read_in_files(set_a_df)\n",
    "set_a_as_number_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in `set_b_df`\n",
    "\n",
    "Read in the second dataset. The naming convention on the files is different than the one on the in CSV which is used as the data dictionary. It's actually worse than in the first dataset so before reading the files we need to clean\n",
    "the naming in the CSV file.\n",
    "\n",
    "For example, a file named `Btraining_extrastole_127_1306764300147_C.wav` in the CSV is actually named `extrastole__127_1306764300147_C.wav` on the hard drive\n",
    "\n",
    "The following group of cells perform the following operations:\n",
    "1. Read files and drop unlabeled test set used on Kaggle\n",
    "2. Perform string operations to match names to their filename on the hard drive\n",
    "3. Run the function `read_in_files` on the files in set_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files and drop unlabeled test set used on Kaggle\n",
    "set_b_df = pd.read_csv('453_923_bundle_archive/set_b.csv')\n",
    "set_b_df = set_b_df[~set_b_df['label'].isna()]\n",
    "print(set_b_df.shape)\n",
    "\n",
    "set_b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform string operations to match names to their filename on the hard drive\n",
    "\n",
    "set_b_df['fname'] = set_b_df['fname'].str.replace('Btraining_', '')\n",
    "set_b_df['fname'] = set_b_df['fname'].str.replace('normal_', 'normal__')\n",
    "set_b_df['fname'] = set_b_df['fname'].str.replace('murmur_', 'murmur__')\n",
    "set_b_df['fname'] = set_b_df['fname'].str.replace('extrastole_', 'extrastole__')\n",
    "set_b_df['fname'] = set_b_df['fname'].str.replace('normal__noisynormal__', 'normal_noisynormal_')\n",
    "set_b_df['fname'] = set_b_df['fname'].str.replace('murmur__noisymurmur__', 'murmur_noisymurmur_')\n",
    "\n",
    "\n",
    "set_b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function `read_in_files` on the files in set_a\n",
    "set_b_as_number_df = read_in_files(set_b_df)\n",
    "set_b_as_number_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine both dataframes \n",
    "\n",
    "Let's combine both dataframes and then call the function which will read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_a_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_b_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([set_a_df, set_b_df], axis=0)\n",
    "combined_df = combined_df.reset_index().drop('index', axis=1)\n",
    "print(combined_df.shape)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_as_number_df = read_in_files(combined_df)\n",
    "combined_as_number_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL WILL RUN FOR A VERY LONG TIME\n",
    "#combined_as_number_df.to_csv('data/audio_as_csv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL WILL RUN FOR A VERY LONG TIME\n",
    "#combined_as_number_df_test = pd.read_csv('data/audio_as_csv.csv')\n",
    "#combined_as_number_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing and reading the dataframe from disk takes much too long. It's better to simply read the individual files and rebuild the dataframe each time.\n",
    "\n",
    "I will define a function named `read_original_data` and place it in a file called `boris_util.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
